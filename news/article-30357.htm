<!doctype html>
<html xml:lang="zh-CN" lang="zh-CN">

<head>
        <link rel="canonical" href="https://hiddifynextnode.github.io/news/article-30357.htm" />
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>【笔记】PyTorch快速入门：基础部分合集_在线工具</title>
        <meta name="description" content="Tensors Tensors贯穿PyTorch始终 和多维数组很相似，一个特点是可以硬件加速 Tensors的初始化 有很多方式   直接给值 data = [[1,2],[3,4]] x_data" />
        <link rel="icon" href="/assets/website/img/hiddifynextnode/favicon.ico" type="image/x-icon"/>

    <meta name="author" content="HiddifyNextNode免费节点官网">
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://hiddifynextnode.github.io/news/article-30357.htm" />
    <meta property="og:site_name" content="HiddifyNextNode免费节点官网" />
    <meta property="og:title" content="【笔记】PyTorch快速入门：基础部分合集_在线工具" />
    <meta property="og:image" content="https://hiddifynextnode.github.io/uploads/20240806/031687adea0405e5a4218938688c7e79.webp" />
        <meta property="og:release_date" content="2024-12-24T09:41:51" />
    <meta property="og:updated_time" content="2024-12-24T09:41:51" />
        <meta property="og:description" content="Tensors Tensors贯穿PyTorch始终 和多维数组很相似，一个特点是可以硬件加速 Tensors的初始化 有很多方式   直接给值 data = [[1,2],[3,4]] x_data" />
        
    <meta name="applicable-device" content="pc,mobile" />
    <meta name="renderer" content="webkit" />
    <meta name="force-rendering" content="webkit" />
    <meta http-equiv="Cache-Control" content="no-transform" />
    <meta name="robots" content="max-image-preview:large" />
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="【笔记】PyTorch快速入门：基础部分合集_在线工具">
    <meta name="format-detection" content="telephone=no">

    <link rel="dns-prefetch" href="https:/www.googletagmanager.com">
    <link rel="dns-prefetch" href="https://www.googleadservices.com">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link rel="dns-prefetch" href="https://pagead2.googlesyndication.com">
    <link rel="dns-prefetch" href="https://cm.g.doubleclick.net">
    <link rel="dns-prefetch" href="https://fonts.googleapis.com">

    <!--/google-fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Poppins:ital,wght@0,300;0,400;0,700;1,400;1,600&display=swap" rel="stylesheet">
    <!--//google-fonts -->
    <!-- Template CSS -->
    <link rel="stylesheet" href="/assets/website/css/hiddifynextnode/style-liberty.css">
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FW3J4WPCDW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FW3J4WPCDW');
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
</head>

<body data-page="detail">
        <!--/Header-->
    <header id="site-header" class="fixed-top">
        <div class="container">
            <nav class="navbar navbar-expand-lg navbar-light stroke py-lg-0">
                                <a class="navbar-brand pe-xl-5 pe-lg-4" href="/">
                    <span class="sublog">Hiddify Next</span> Node
                </a>
                                <button class="navbar-toggler collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#navbarScroll" aria-controls="navbarScroll" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon fa icon-expand fa-bars"></span>
                    <span class="navbar-toggler-icon fa icon-close fa-times"></span>
                </button>
                <div class="collapse navbar-collapse" id="navbarScroll">
                    <ul class="navbar-nav me-lg-auto my-2 my-lg-0 navbar-nav-scroll">
                                                <li class="nav-item">
                            <a class="nav-link" href="/">首页</a>
                        </li>
                                                <li class="nav-item">
                            <a class="nav-link" href="/free-nodes/">免费节点</a>
                        </li>
                                                <li class="nav-item">
                            <a class="nav-link" href="/paid-subscribe/">推荐机场</a>
                        </li>
                                                <li class="nav-item">
                            <a class="nav-link" href="/news/">新闻资讯</a>
                        </li>
                                                
                        <li class="nav-item">
                            <a class="nav-link" href="#">关于</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#">联系</a>
                        </li>
                    </ul>
                
                </div>
                <!-- toggle switch for light and dark theme -->
                <div class="mobile-position">
                    <nav class="navigation">
                        <div class="theme-switch-wrapper">
                            <label class="theme-switch" for="checkbox">
                                <input type="checkbox" id="checkbox">
                                <div class="mode-container">
                                    <i class="gg-sun"></i>
                                    <i class="gg-moon"></i>
                                </div>
                            </label>
                        </div>
                    </nav>
                </div>
                <!-- //toggle switch for light and dark theme -->
            </nav>
        </div>
    </header>
    <!--//Header-->
    <!-- breadcrumb -->
    <section class="w3l-about-breadcrumb">
        <div class="breadcrumb-bg breadcrumb-bg-about">
            <div class="container py-lg-5 py-sm-4">
                <div class="w3breadcrumb-gids text-center">
                    <div class="w3breadcrumb-info mt-5">
                        <h1 class="w3ltop-title pt-4">【笔记】PyTorch快速入门：基础部分合集_在线工具</h1>
                        <ul class="breadcrumbs-custom-path">
                            <li><a href="/">首页</a></li>
                            <li><a href="/news/"><span class="fas fa-angle-double-right mx-2"></span>  新闻资讯</a></li>
                            <li class="active"><span class="fas fa-angle-double-right mx-2"></span> 正文 </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    
    <!--/tabs-faqs-->
    <section class="w3l-products w3l-faq-block py-5" id="projects">
        <div class="container py-md-5 py-2">
            <div class="row">
                <div class="col-md-9">
                                    <input type="hidden" id="share-website-info" data-name="" data-url="">
                  				  				  				</h1> <h2 id="tensors">Tensors</h2> <p>Tensors贯穿PyTorch始终</p> <p>和多维数组很相似，一个特点是可以硬件加速</p> <h3 id="tensors的初始化">Tensors的初始化</h3> <p>有很多方式</p> <ul> <li> <p>直接给值</p> <pre><code class="language-python">data = [[1,2],[3,4]] x_data = torch.tensor(data)</code></pre> </li> <li> <p>从NumPy数组转来</p> <pre><code class="language-python">np_arr = np.array(data) x_np = torch.from_numpy(np_array)</code></pre> </li> <li> <p>从另一个Tensor</p> <pre><code class="language-python">x_ones = torch.ones_like(x_data)</code></pre> </li> <li> <p>赋01或随机值</p> <pre><code class="language-python">shape = (2,3,) rand_tensor = torch.rand(shape) ones_tensor = torch.ones(shape) zeros_tensor = torch.zeros(shape)</code></pre> </li> </ul> <h3 id="tensors的属性">Tensors的属性</h3> <pre><code class="language-python">tensor = torch.rand(3,4) print(f"Shape of tensor: {tensor.shape}") print(f"Datatype of tensor: {tensor.dtype}") print(f"Device tensor is stored on: {tensor.device}")</code></pre> <p>shape维度，dtype元素类型，device运行设备(cpu/gpu)</p> <h3 id="tensors的操作">Tensors的操作</h3> <p>使用GPU的方法</p> <pre><code class="language-python">if torch.cuda_is_available():   tensor = tensor.to("cuda")</code></pre> <p>各种操作</p> <ul> <li> <p>索引和切片</p> <pre><code class="language-python">tensor = torch.ones(4,4) print(tensor[0]) 			#第一行（0开始） print(tensor[;,0])		#第一列（0开始） print(tensor[...,-1])	#最后一列</code></pre> </li> <li> <p>连接</p> <pre><code class="language-python">t1 = torch.cat([tensor,tensor],dim=1) #沿着第一维的方向拼接</code></pre> </li> <li> <p>矩阵乘法</p> <p>三种办法，类似于运算符重载、成员函数和非成员函数</p> <pre><code class="language-python">y1 = tensor @ tensor y2 = tensor.matmul(tensor.T) y3 = torch.rand_like(tensor) torch.matmul(tensor,tensor.T,out=y3)</code></pre> </li> <li> <p>点乘</p> <p>类似，也是三种办法</p> <pre><code class="language-python">z1 = tensor * tensor z2 = tensor.mul(tensor) z3 = torch.rand_like(tensor) torch.mul(tensor,tensor,out=z3)</code></pre> </li> <li> <p>单元素tensor求值</p> <pre><code class="language-python">agg = tensor.sum() agg_item = agg.item() print(agg_item,type(agg_item))</code></pre> </li> <li> <p>In-place 操作</p> <p>就是会改变成员内容的成员函数，以下划线结尾</p> <pre><code class="language-python">tensor.add_(5) #每个元素都+5</code></pre> <p>节约内存，但是会丢失计算前的值，不推荐使用。</p> </li> </ul> <h3 id="和numpy的联系">和NumPy的联系</h3> <ul> <li> <p>Tensor转NumPy数组</p> <pre><code>t = torch.ones(5) n = t.numpy()</code></pre> <p><mark>注意</mark>，这个写法类似引用，没有新建内存，二者修改同步</p> </li> <li> <p>NumPy数组转tensor</p> <pre><code class="language-python">n = np.ones(5) t = torch.from_numpy(n)</code></pre> <p>同样是引用，一个的修改会对另一个有影响</p> </li> </ul> <h2 id="数据集和数据加载器">数据集和数据加载器</h2> <p>处理数据的代码通常很杂乱，难以维护，我们希望这部分代码和主代码分离。</p> <h3 id="加载数据集">加载数据集</h3> <p>以FasnionMNIST为例，我们需要四个参数</p> <ul> <li> <p>root是路径</p> </li> <li> <p>Train区分训练集还是测试集</p> </li> <li> <p>download表示如果root找不到，就从网上下载</p> </li> <li> <p>transform表明数据的转换方式</p> </li> </ul> <pre><code class="language-python">import torch from torch.utils.data import Dataset from torchvision import datasets from torchvision.transforms import ToTensor import matplotlib.pyplot as plt  training_data = datasets.FansionMNIST( 	root = "data",   train = True,   download = True,   transform = ToTensor() )  test_data = datasets.FansionMNIST( 	root = "data",   train = False,   download = True,   transform = ToTensor() )</code></pre> <h3 id="标号和可视化">标号和可视化</h3> <pre><code class="language-python">labels_map = {     0: "T-Shirt",     1: "Trouser",     2: "Pullover",     3: "Dress",     4: "Coat",     5: "Sandal",     6: "Shirt",     7: "Sneaker",     8: "Bag",     9: "Ankle Boot", } figure = plt.figure(figsize=(8, 8)) cols, rows = 3, 3 for i in range(1, cols * rows + 1):     sample_idx = torch.randint(len(training_data), size=(1,)).item()     img, label = training_data[sample_idx]     figure.add_subplot(rows, cols, i)     plt.title(labels_map[label])     plt.axis("off")     plt.imshow(img.squeeze(), cmap="gray") plt.show()</code></pre> <h3 id="自己创建数据集类">自己创建数据集类</h3> <p>必须实现三个函数<code>__init__</code>,<code>__len__</code>,<code>__getitem__</code></p> <pre><code class="language-python">import os import pandas as pd from torchvision.io import read_image  class CustomImageDataset(Dataset):     def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):         self.img_labels = pd.read_csv(annotations_file)         self.img_dir = img_dir         self.transform = transform         self.target_transform = target_transform      def __len__(self):         return len(self.img_labels)      def __getitem__(self, idx):         img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])         image = read_image(img_path)         label = self.img_labels.iloc[idx, 1]         if self.transform:             image = self.transform(image)         if self.target_transform:             label = self.target_transform(label)         return image, label</code></pre> <p><code>__init__</code>类似于构造函数</p> <p><code>__len__</code>求数据个数</p> <p><code>__getitem__</code>按下标找数据和标签，类似重载[]</p> <h3 id="用dataloaders准备数据用于训练">用DataLoaders准备数据用于训练</h3> <p>DataLoaders主要做3件事，将数据划分为小batches，随机打乱数据，和多核处理。</p> <pre><code class="language-python">from torch.utils.data import DataLoader train_dataloader = DataLoader(training_data,batch_size = 64,shuffle=True) test_dataloader = DataLoader(test_data,batch_size = 64,shuffle=True)</code></pre> <h3 id="用dataloader进行迭代训练">用DataLoader进行迭代训练</h3> <pre><code class="language-python"># 展示图像和标签 train_features, train_labels = next(iter(train_dataloader)) print(f"Feature batch shape: {train_features.size()}") print(f"Labels batch shape: {train_labels.size()}") img = train_features[0].squeeze() label = train_labels[0] plt.imshow(img, cmap="gray") plt.show() print(f"Label: {label}")</code></pre> <h2 id="transforms">Transforms</h2> <p>让数据变形成需要的形式</p> <p><code>transform</code>指定feature的变形</p> <p><code>target_transform</code>指定标签的变形</p> <p>比如，需要数据从PIL Image变成Tensors，标签从整数变成one-hot encoded tensors</p> <pre><code class="language-python">import torch from torchvision import datasets from torchvision.transforms import ToTensor, Lambda  ds = datasets.FashionMNIST(     root="data",     train=True,     download=True,     transform=ToTensor(),     target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)) )</code></pre> <p>这里用了两个技术，<code>ToTensor()</code>和<code>Lambda</code>表达式</p> <p><code>ToTensor()</code>将PIL images或者NumPy数组转化成FloatTensor，每个像素的灰度转化到[0,1]范围内</p> <p><code>Lambda</code>类似C++里的Lambda表达式，我们需要将整数转化为 one-hot encoded tensor，就先创建一个长度为数据标签类型的全0的Tensor，然后用scatter_()把第y个值改为1。注意到，scatter的index接受的参数也是Tensor，可见Tensor的广泛使用。</p> <h2 id="神经网络">神经网络</h2> <p>神经网络是一些层或者模块，对数据进行处理。</p> <p><code>torch.nn</code>提供了诸多构造神经网络的模块，模块化的结构方便了管理复杂结构。</p> <p>接下来以在FashionMNIST上构造一个图像分类器为例。</p> <pre><code class="language-python">import os import torch from torch import nn from torch.utils.data import DataLoader from torchvision import datasets, transforms</code></pre> <h3 id="准备训练设备">准备训练设备</h3> <p>有GPU用GPU，没有用CPU</p> <pre><code class="language-python">device = "cuda" if torch.cuda.is_available() else "cpu" print(f"Using {device} device")</code></pre> <h3 id="定义网络的类">定义网络的类</h3> <p>我们的网络从<code>nn.Module</code>继承来</p> <pre><code class="language-python">class NeuralNetwork(nn.Module):     def __init__(self):         super(NeuralNetwork, self).__init__()         self.flatten = nn.Flatten()         self.linear_relu_stack = nn.Sequential(             nn.Linear(28*28, 512),             nn.ReLU(),             nn.Linear(512, 512),             nn.ReLU(),             nn.Linear(512, 10),         )      def forward(self, x):         x = self.flatten(x)         logits = self.linear_relu_stack(x)         return logits</code></pre> <p>然后创建一个实例（对象），把它放到device上</p> <pre><code class="language-python">model = NeuralNetwork().to(device) print(model)</code></pre> <p>跑一下的结果</p> <pre><code class="language-shell">Using cpu device NeuralNetwork(   (flatten): Flatten(start_dim=1, end_dim=-1)   (linear_relu_stack): Sequential(     (0): Linear(in_features=784, out_features=512, bias=True)     (1): ReLU()     (2): Linear(in_features=512, out_features=512, bias=True)     (3): ReLU()     (4): Linear(in_features=512, out_features=10, bias=True)   ) )</code></pre> <p>结果是返回值的softmax，这是个10维的概率，找最大的就是预测结果</p> <pre><code class="language-python">X = torch.rand(1, 28, 28, device=device) logits = model(X) pred_probab = nn.Softmax(dim=1)(logits) y_pred = pred_probab.argmax(1) print(f"Predicted class: {y_pred}")</code></pre> <h3 id="模型的layers">模型的layers</h3> <p>以3张28x28的图像为例，分析它在network里的状态</p> <pre><code class="language-python">input_image = torch.rand(3,28,28) print(input_image.size()) '''  torch.Size([3,28,28]) '''</code></pre> <h4 id="nnflatten">nn.Flatten</h4> <p>Flatten顾名思义，扁平化，用于将2维tensor转为1维的</p> <pre><code class="language-python">flatten = nn.Flatten() flat_image = flatten(input_image) print(flag_image.size()) '''  torch.Size([3,784]) '''</code></pre> <h4 id="nnlinear">nn.Linear</h4> <p>Linear，做线性变换的</p> <pre><code class="language-python">layer1 = nn.Linear(in_features=28*28,out_features=20) hidden1 = layer1(flag_image) print(hidden1.size()) ''' torch.Size([3,20]) '''</code></pre> <h4 id="nnrelu">nn.ReLU</h4> <p>非线性激活函数，在Linear层后，增加非线性，让神经网络学到更多的信息</p> <pre><code class="language-python">hidden1 = nn.ReLU()(hidden1)</code></pre> <h4 id="nnsequential">nn.Sequential</h4> <p>Sequential，序列的，类似于把layers一层一层摆着</p> <pre><code class="language-python">seq_modules = nn.Sequential(     flatten,     layer1,     nn.ReLU(),     nn.Linear(20, 10) ) input_image = torch.rand(3,28,28) logits = seq_modules(input_image)</code></pre> <h4 id="nnsoftmax">nn.Softmax</h4> <p>最后一层的结果返回一个在[-inf,inf]的值logits，通过softmax层后，映射到[0,1]</p> <p>这样[0,1]的值可以作为概率输出，dim指定和为1的维度</p> <pre><code class="language-python">softmax = nn.Softmax(dim=1) pred_probab = softmax(logits)</code></pre> <h3 id="模型的参数">模型的参数</h3> <p>这些layers是参数化的，就是说在训练中weights和biases不断被优化</p> <p>以下的代码输出这个模型里的所有参数值</p> <pre><code class="language-python">for name, param in model.named_parameters():   print(name,param.size(),param[:2])</code></pre> <h2 id="自动求导">自动求导</h2> <p>训练神经网络的时候，最常用的是反向传播，模型参数根据loss functoin的梯度进行调整。</p> <p>为了求梯度，也就是求导，我们使用<code>torch.autograd</code>。</p> <p>考虑就一个layer的网络，输入x，参数w和b，以及一个loss function，也就是</p> <pre><code class="language-python">import torch  x = torch.ones(5)  # input tensor y = torch.zeros(3)  # expected output w = torch.randn(5, 3, requires_grad=True) b = torch.randn(3, requires_grad=True) z = torch.matmul(x, w)+b loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)</code></pre> <h3 id="tensors-functions-and-computational-graph">Tensors, Functions and Computational Graph</h3> <p>考虑这个过程的Computational Graph，如下</p> <p><img decoding="async" src="https://pytorch.org/tutorials/_images/comp-graph.png" alt="【笔记】PyTorch快速入门：基础部分合集_在线工具"></p> <p>这个一定是<strong>DAG</strong>（有向无环图）</p> <p>为了计算loss在w和b方向上的梯度，我们给他们设置<code>requires_grad</code></p> <pre><code class="language-python">w.requires_grad_(True) b.requires_grad_(True)</code></pre> <p>Functions实际上是对象，有计算正向值和反向导数的成员。</p> <pre><code class="language-python">print(z.grad_fn) print(loss.grad_fn)</code></pre> <h3 id="计算梯度">计算梯度</h3> <p>我们要计算Loss对w和b的偏导，只需要使用</p> <pre><code class="language-python">loss.backward()</code></pre> <p>然后就得到了</p> <pre><code class="language-python">print(w.grad) print(b.grad)</code></pre> <p><mark>注意</mark>：</p> <ul> <li>我们只能计算图里叶子的梯度，内部的点不能算</li> <li>一张图只能计算一次梯度，要保留节点的话，backward要传<code>retain_graph=True</code></li> </ul> <pre><code class="language-python">import torch x = torch.randn((1,4),dtype=torch.float32,requires_grad=True) y = x ** 2 z = y * 4 print(x) print(y) print(z) loss1 = z.mean() loss2 = z.sum() print(loss1,loss2) loss1.backward()    # 这个代码执行正常，但是执行完中间变量都free了，所以下一个出现了问题 print(loss1,loss2) loss2.backward()    # 这时会引发错误</code></pre> <p>所以要把loss1的那行改成</p> <pre><code class="language-python">loss1.backward(retain_graph=True)</code></pre> <h3 id="不计算梯度">不计算梯度</h3> <p>有些时候我们不需要计算梯度，比如模型已经训好了，只需要正向用</p> <p>这个时候算梯度就很拖累时间，所以要禁用梯度</p> <pre><code class="language-python">z = torch.matmul(x, w)+b print(z.requires_grad)  with torch.no_grad():     z = torch.matmul(x, w)+b print(z.requires_grad) ''' True False '''</code></pre> <p>另一个办法是用<code>.detach()</code></p> <pre><code class="language-python">z = torch.matmul(x, w)+b z_det = z.detach() print(z_det.requires_grad) ''' False '''</code></pre> <h3 id="tensor输出和雅克比积">tensor输出和雅克比积</h3> <p>如果函数的输出是tensor，就不能简单算梯度了</p> <p>结果是一个矩阵（其实就是依次遍历x和y的分量，求偏导）</p> <div class="math display">\[J=\left(\begin{array}{ccc}\frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{1}}{\partial x_{n}} \\ \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial y_{m}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}\end{array}\right)<br /> \]</div> <p>PyTorch不计算J的原始值，而是给一个<span class="math inline">\(v\)</span>，计算<span class="math inline">\(v^T\cdot J\)</span>，输出接口是统一的</p> <p>具体来说，把v当参数传进去</p> <pre><code class="language-python">inp = torch.eye(5, requires_grad=True) out = (inp+1).pow(2) out.backward(torch.ones_like(inp), retain_graph=True)</code></pre> <h2 id="优化模型参数">优化模型参数</h2> <p>有了模型，接下来要进行训练、验证和测试。</p> <h3 id="前置代码">前置代码</h3> <p>首先要加载数据，建立模型</p> <pre><code class="language-python">import torch from torch import nn from torch.utils.data import DataLoader from torchvision import datasets from torchvision.transforms import ToTensor, Lambda  training_data = datasets.FashionMNIST(     root="data",     train=True,     download=True,     transform=ToTensor() )  test_data = datasets.FashionMNIST(     root="data",     train=False,     download=True,     transform=ToTensor() )  train_dataloader = DataLoader(training_data, batch_size=64) test_dataloader = DataLoader(test_data, batch_size=64)  class NeuralNetwork(nn.Module):     def __init__(self):         super(NeuralNetwork, self).__init__()         self.flatten = nn.Flatten()         self.linear_relu_stack = nn.Sequential(             nn.Linear(28*28, 512),             nn.ReLU(),             nn.Linear(512, 512),             nn.ReLU(),             nn.Linear(512, 10),         )      def forward(self, x):         x = self.flatten(x)         logits = self.linear_relu_stack(x)         return logits  model = NeuralNetwork()</code></pre> <h3 id="超参数">超参数</h3> <p>定义三个超参数</p> <ul> <li>Epochs数：数据集迭代次数</li> <li>Batch size：单次训练样本数</li> <li>Learning Rate：学习速度</li> </ul> <h3 id="优化循环">优化循环</h3> <p>接下来，我们进行多轮的优化，每轮叫一个epoch</p> <p>每个epoch包含两部分，训练loop和验证/测试loop</p> <h4 id="loss-function">Loss Function</h4> <p>PyTorch提供常见的Loss Functions</p> <ul> <li>nn.MSELoss (Mean Square Error)</li> <li>nn.NLLLoss (Negative Log Likelihood)</li> <li>nn.CrossEntropyLoss (交叉熵)</li> </ul> <p>我们使用交叉熵，把原始结果logits放进去</p> <pre><code class="language-python">loss_fn = nn.CrossEntropyLoss()</code></pre> <h4 id="optimizer">Optimizer</h4> <p>初始化优化器，给它需要优化的参数，和超参数Learning Rate</p> <pre><code class="language-python">optimizer = torch.optim.SGC(model.parameters(),lr = learning_rate)</code></pre> <p>优化器在每个epoch里做三件事</p> <ul> <li><code>optimizer.zero_grad()</code>将梯度清零</li> <li><code>loss.backward()</code>进行反向传播</li> <li><code>optimizer.step()</code>根据梯度调整参数</li> </ul> <h3 id="完整实现">完整实现</h3> <p>在<code>train_loop</code>里训练，<code>test_loop</code>里测试</p> <pre><code class="language-python">import torch from torch import nn from torch.utils.data import DataLoader from torchvision import datasets from torchvision.transforms import ToTensor, Lambda  training_data = datasets.FashionMNIST(     root="data",     train=True,     download=True,     transform=ToTensor() )  test_data = datasets.FashionMNIST(     root="data",     train=False,     download=True,     transform=ToTensor() )  train_dataloader = DataLoader(training_data, batch_size=64) test_dataloader = DataLoader(test_data, batch_size=64)  class NeuralNetwork(nn.Module):     def __init__(self):         super(NeuralNetwork, self).__init__()         self.flatten = nn.Flatten()         self.linear_relu_stack = nn.Sequential(             nn.Linear(28*28, 512),             nn.ReLU(),             nn.Linear(512, 512),             nn.ReLU(),             nn.Linear(512, 10),         )      def forward(self, x):         x = self.flatten(x)         logits = self.linear_relu_stack(x)         return logits  model = NeuralNetwork()  learning_rate = 1e-3 batch_size = 64 epochs = 5  # Initialize the loss function loss_fn = nn.CrossEntropyLoss()  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  def train_loop(dataloader, model, loss_fn, optimizer):     size = len(dataloader.dataset)     for batch, (X, y) in enumerate(dataloader):         # Compute prediction and loss         pred = model(X)         loss = loss_fn(pred, y)          # Backpropagation         optimizer.zero_grad()         loss.backward()         optimizer.step()          if batch % 100 == 0:             loss, current = loss.item(), batch * len(X)             print(f"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]")   def test_loop(dataloader, model, loss_fn):     size = len(dataloader.dataset)     num_batches = len(dataloader)     test_loss, correct = 0, 0      with torch.no_grad():         for X, y in dataloader:             pred = model(X)             test_loss += loss_fn(pred, y).item()             correct += (pred.argmax(1) == y).type(torch.float).sum().item()      test_loss /= num_batches     correct /= size     print(f"Test Error: \n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \n")  loss_fn = nn.CrossEntropyLoss() optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  epochs = 10 for t in range(epochs):     print(f"Epoch {t + 1}\n-------------------------------")     train_loop(train_dataloader, model, loss_fn, optimizer)     test_loop(test_dataloader, model, loss_fn) print("Done!")</code></pre> <h2 id="保存和加载模型">保存和加载模型</h2> <p>如何保存和加载训好的模型？</p> <pre><code class="language-python">import torch import torchvision.models as models</code></pre> <h3 id="保存和加载模型权重">保存和加载模型权重</h3> <p>通过<code>torch.save</code>方法，可以将模型保存到<code>state_dict</code>类型的字典里。</p> <pre><code class="language-python">model = models.vgg16(pretrained=True) torch.save(model.state_dict(), 'model_weights.pth')</code></pre> <p>而要加载的话，需要先构造相同类型的模型，然后把参数加载进去</p> <pre><code class="language-python">model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights model.load_state_dict(torch.load('model_weights.pth')) model.eval()</code></pre> <p>注意，一定要调一下<code>model.eval()</code>，防止后续出错</p> <h3 id="保存和加载模型-1">保存和加载模型</h3> <p>上一种方法里，需要先实例化模型，再导入权值</p> <p>有没有办法直接保存和加载整个模型呢？</p> <p>我们用不传<code>mode.state_dict()</code>参数，改为<code>model</code></p> <p>保存方式：</p> <pre><code class="language-python">torch.save(model,'model.pth')</code></pre> <p>加载方式：</p> <pre><code class="language-python">model = torch.load('model.pth')</code></pre> 			                <div class="clearfix"></div>
                <div class="col-md-12 mt-5">
                                        <p>上一个：<a href="/news/article-29879.htm">动物疫苗能放冰箱吗 动物疫苗能放冰箱吗多久</a></p>
                                        <p>下一个：<a href="/news/article-30358.htm">动物疫苗接种方法有哪些类型图片（动物疫苗接种技术）</a></p>
                                    </div>
                                </div>
                <div class="col-md-3">
                    <div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">热门文章</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2"><a href="/news/article-41007.htm" title="MYSQL存储时间数据的数据类型选择">MYSQL存储时间数据的数据类型选择</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-1-26-free-high-speed-nodes.htm" title="1月26日 | HiddifyNextNode机场节点订阅每天更新22.9M/S免费节点订阅链接">1月26日 | HiddifyNextNode机场节点订阅每天更新22.9M/S免费节点订阅链接</a></li>
                        <li class="py-2"><a href="/news/article-26610.htm" title="动物医院社会实践3000字 动物医院社会实践3000字怎么写">动物医院社会实践3000字 动物医院社会实践3000字怎么写</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-11-17-node-share-links.htm" title="11月17日 | HiddifyNextNode机场节点订阅每天更新21.3M/S免费节点订阅链接">11月17日 | HiddifyNextNode机场节点订阅每天更新21.3M/S免费节点订阅链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-1-1-free-subscribe-node.htm" title="1月1日 | HiddifyNextNode机场节点订阅每天更新21M/S免费节点订阅链接">1月1日 | HiddifyNextNode机场节点订阅每天更新21M/S免费节点订阅链接</a></li>
                        <li class="py-2"><a href="/news/article-39507.htm" title="Java 9中Collectors.filtering()方法的重要性">Java 9中Collectors.filtering()方法的重要性</a></li>
                        <li class="py-2"><a href="/news/article-39508.htm" title="国产兽药厂家排名前十强企业（国内兽药厂家）">国产兽药厂家排名前十强企业（国内兽药厂家）</a></li>
                        <li class="py-2"><a href="/free-nodes/2024-12-27-hiddify-next-node.htm" title="12月27日 | HiddifyNextNode机场节点订阅每天更新18.9M/S免费节点订阅链接">12月27日 | HiddifyNextNode机场节点订阅每天更新18.9M/S免费节点订阅链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-1-12-today-hiddify-next-node.htm" title="1月12日 | HiddifyNextNode机场节点订阅每天更新22.8M/S免费节点订阅链接">1月12日 | HiddifyNextNode机场节点订阅每天更新22.8M/S免费节点订阅链接</a></li>
                        <li class="py-2"><a href="/news/article-34647.htm" title="流浪狗领养小程序（领养流浪狗要办什么手续）">流浪狗领养小程序（领养流浪狗要办什么手续）</a></li>
                    </ul>
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">归纳</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">6</span> <a href="/date/2025-02/" title="2025-02 归档">2025-02</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">93</span> <a href="/date/2025-01/" title="2025-01 归档">2025-01</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">93</span> <a href="/date/2024-12/" title="2024-12 归档">2024-12</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">30</span> <a href="/date/2024-11/" title="2024-11 归档">2024-11</a></h4>
            </li>
                    </ul>
    </div>
</div>

                </div>
            </div>
        </div>
    </section>
    <!--//tabs-faqs-->
    
        <!-- footer -->
    <section class="w3l-footer-29-main">
        <!-- copyright -->
        <section class="w3l-copyright text-center">
            <div class="container">
                            <p>
                                <a href="/">首页</a> | 
                                <a href="/free-node/">免费节点</a> | 
                                <a href="/news/">新闻资讯</a> |
                                <a href="/about-us.htm">关于我们</a> |
                                <a href="/disclaimer.htm">免责申明</a> |
                                <a href="/privacy.htm">隐私申明</a> |
                                <a href="/sitemap.xml">网站地图</a>
                            </p>
                <p class="copy-footer-29">HiddifyNextNode免费节点官网 版权所有 Powered by WordPress</p>
            </div>
            <!-- move top -->
            <button onclick="topFunction()" id="movetop" title="Go to top">
                <span class="fas fa-arrow-up"></span>
            </button>
            <script>
            // When the user scrolls down 20px from the top of the document, show the button
            window.onscroll = function() {
                scrollFunction()
            };

            function scrollFunction() {
                if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
                    document.getElementById("movetop").style.display = "block";
                } else {
                    document.getElementById("movetop").style.display = "none";
                }
            }

            // When the user clicks on the button, scroll to the top of the document
            function topFunction() {
                document.body.scrollTop = 0;
                document.documentElement.scrollTop = 0;
            }
            </script>
            <!-- /move top -->
        </section>
        <!-- //copyright -->
    </section>
    <!-- //footer -->
    <!-- Js scripts -->
    <!-- Template JavaScript -->
    <script src="/assets/website/js/frontend/hiddifynextnode/jquery-3.3.1.min.js"></script>
    <script src="/assets/website/js/frontend/hiddifynextnode/theme-change.js"></script>
    <!-- /typig-text-->
    <script>
    const typedTextSpan = document.querySelector(".typed-text");
    const cursorSpan = document.querySelector(".cursor");

    const textArray = ["Creative Agency", "Digital Marketing", "Brand Identity"];
    const typingDelay = 200;
    const erasingDelay = 10;
    const newTextDelay = 100; // Delay between current and next text
    let textArrayIndex = 0;
    let charIndex = 0;

    function type() {
        if (charIndex < textArray[textArrayIndex].length) {
            if (!cursorSpan.classList.contains("typing")) cursorSpan.classList.add("typing");
            typedTextSpan.textContent += textArray[textArrayIndex].charAt(charIndex);
            charIndex++;
            setTimeout(type, typingDelay);
        } else {
            cursorSpan.classList.remove("typing");
            setTimeout(erase, newTextDelay);
        }
    }

    function erase() {
        if (charIndex > 0) {
            // add class 'typing' if there's none
            if (!cursorSpan.classList.contains("typing")) {
                cursorSpan.classList.add("typing");
            }
            typedTextSpan.textContent = textArray[textArrayIndex].substring(0, 0);
            charIndex--;
            setTimeout(erase, erasingDelay);
        } else {
            cursorSpan.classList.remove("typing");
            textArrayIndex++;
            if (textArrayIndex >= textArray.length) textArrayIndex = 0;
            setTimeout(type, typingDelay);
        }
    }

    document.addEventListener("DOMContentLoaded", function() { // On DOM Load initiate the effect
        if (textArray.length) setTimeout(type, newTextDelay + 250);
    });
    </script>
    <!-- //typig-text-->
    <script src="/assets/website/js/frontend/hiddifynextnode/jquery-1.9.1.min.js"></script>
    <!-- faq -->
    <script>
    const items = document.querySelectorAll(".accordion button");

    function toggleAccordion() {
        const itemToggle = this.getAttribute('aria-expanded');

        for (i = 0; i < items.length; i++) {
            items[i].setAttribute('aria-expanded', 'false');
        }

        if (itemToggle == 'false') {
            this.setAttribute('aria-expanded', 'true');
        }
    }

    items.forEach(item => item.addEventListener('click', toggleAccordion));
    </script>
    <!-- //faq -->
    <script src="/assets/website/js/frontend/hiddifynextnode/circles.js"></script>
    <!-- owlcarousel -->
    <script src="/assets/website/js/frontend/hiddifynextnode/owl.carousel.js"></script>
    <!-- script for banner slider-->
    <script>
    $(document).ready(function() {
        $('.owl-one').owlCarousel({
            loop: true,
            margin: 0,
            nav: false,
            responsiveClass: false,
            autoplay: false,
            autoplayTimeout: 5000,
            autoplaySpeed: 1000,
            autoplayHoverPause: false,
            responsive: {
                0: {
                    items: 1
                },
                480: {
                    items: 1
                },
                667: {
                    items: 1
                },
                1000: {
                    items: 1
                }
            }
        })

        $('.owl-carousel .owl-dots, .owl-carousel .owl-nav').hide();
    })
    </script>
    <!-- //script -->
    
    <!-- //script for tesimonials carousel slider -->
    <!-- video popup -->
    <script src="/assets/website/js/frontend/hiddifynextnode/jquery.magnific-popup.min.js"></script>
    <script>
    $(document).ready(function() {
        $('.popup-with-zoom-anim').magnificPopup({
            type: 'inline',

            fixedContentPos: false,
            fixedBgPos: true,

            overflowY: 'auto',

            closeBtnInside: true,
            preloader: false,

            midClick: true,
            removalDelay: 300,
            mainClass: 'my-mfp-zoom-in'
        });

        $('.popup-with-move-anim').magnificPopup({
            type: 'inline',

            fixedContentPos: false,
            fixedBgPos: true,

            overflowY: 'auto',

            closeBtnInside: true,
            preloader: false,

            midClick: true,
            removalDelay: 300,
            mainClass: 'my-mfp-slide-bottom'
        });
    });
    </script>
    <!-- //video popup -->
    <!-- MENU-JS -->
    <script>
    $(window).on("scroll", function() {
        var scroll = $(window).scrollTop();

        if (scroll >= 80) {
            $("#site-header").addClass("nav-fixed");
        } else {
            $("#site-header").removeClass("nav-fixed");
        }
    });

    //Main navigation Active Class Add Remove
    $(".navbar-toggler").on("click", function() {
        $("header").toggleClass("active");
    });
    $(document).on("ready", function() {
        if ($(window).width() > 991) {
            $("header").removeClass("active");
        }
        $(window).on("resize", function() {
            if ($(window).width() > 991) {
                $("header").removeClass("active");
            }
        });
    });
    </script>
    <!-- //MENU-JS -->
    <!-- disable body scroll which navbar is in active -->
    <script>
    $(function() {
        $('.navbar-toggler').click(function() {
            $('body').toggleClass('noscroll');
        })
    });
    </script>
    <!-- //disable body scroll which navbar is in active -->
    <!-- //bootstrap -->
    <script src="/assets/website/js/frontend/hiddifynextnode/bootstrap.min.js"></script>
    <script src="https://www.freeclashnode.com/assets/js/frontend/invite-url.js"></script><script src="/assets/website/js/frontend/G.js"></script>
</body>

</html>